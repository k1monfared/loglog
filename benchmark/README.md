# LogLog GUI Performance Benchmarking System

A comprehensive performance monitoring and regression detection system for LogLog GUI development.

## ğŸ¯ Purpose

This benchmarking system tracks performance metrics across different versions to:
- **Detect regressions** before they reach production
- **Measure optimization impact** quantitatively  
- **Guide development priorities** based on performance data
- **Ensure scalability** as features are added

## ğŸ“Š What It Measures

### File Opening Performance
- Small files (~10 items)
- Medium files (~50 items)  
- Large files (~200 items)
- Extra large files (~500 items)
- Huge files (~1000 items)
- Massive files (~2000 items)

### Tab Switching Performance
- 2, 3, 5, and 8 tabs open simultaneously
- Switch time between different tabs
- Memory usage with multiple tabs

### Folding/Unfolding Operations
- Fold to level 1, 2, 3
- Unfold all operations
- Performance at different tree depths

## ğŸš€ Quick Start

### Run Benchmark
```bash
# Automatic mode (commits changes and runs benchmark)
./benchmark/run_benchmark.sh

# Manual mode (run benchmark without committing)
cd benchmark
python3 benchmark_runner.py
```

### Generate Performance Report
```bash
cd benchmark
python3 performance_report.py
```

### Generate Test Files
```bash
cd benchmark
python3 generate_test_files.py
```

## ğŸ“ Files Structure

```
benchmark/
â”œâ”€â”€ run_benchmark.sh           # Main benchmark runner script
â”œâ”€â”€ benchmark_runner.py        # Core benchmarking engine
â”œâ”€â”€ generate_test_files.py     # Creates test LogLog files
â”œâ”€â”€ performance_report.py      # Generates analysis reports
â”œâ”€â”€ performance_results.csv    # Historical performance data
â”œâ”€â”€ reports/                   # Generated performance reports
â”œâ”€â”€ small.log                  # Test file (~10 items)
â”œâ”€â”€ medium.log                 # Test file (~50 items)
â”œâ”€â”€ large.log                  # Test file (~200 items)
â”œâ”€â”€ xlarge.log                 # Test file (~500 items)
â”œâ”€â”€ huge.log                   # Test file (~1000 items)
â”œâ”€â”€ massive.log                # Test file (~2000 items)
â””â”€â”€ README.md                  # This file
```

## ğŸ“ˆ Understanding Results

### Performance CSV Format
```csv
timestamp,version_id,test_type,file_name,file_size_bytes,line_count,num_tabs,level,mean_time_ms,median_time_ms,min_time_ms,max_time_ms,std_time_ms,memory_mb
```

### Key Metrics
- **mean_time_ms**: Average execution time across multiple runs
- **std_time_ms**: Standard deviation (consistency indicator)
- **memory_mb**: Memory usage during operation
- **version_id**: Git commit hash for version tracking

### Test Types
- `file_open`: File opening performance
- `tab_switch`: Tab switching performance  
- `fold_level`: Folding operations
- `unfold_level`: Unfolding operations

## ğŸ” Regression Detection

The system automatically detects performance regressions by:
1. Comparing latest run with previous run
2. Flagging >10% performance degradation
3. Tracking long-term performance trends
4. Generating actionable recommendations

### Example Output
```
=== Performance Comparison ===
Comparing abc123 â†’ def456
  file_open      :  45.23ms â†’  52.18ms â¬†ï¸  +15.4%  âš ï¸ REGRESSION
  tab_switch     :  12.45ms â†’  11.32ms â¬‡ï¸   -9.1%  âœ… IMPROVED  
  fold_level     :  23.67ms â†’  18.91ms â¬‡ï¸  -20.1%  âœ… IMPROVED
```

## ğŸ› ï¸ Development Workflow

### Before Making Changes
```bash
# Run baseline benchmark
./benchmark/run_benchmark.sh
```

### After Making Changes
```bash
# Run benchmark to measure impact
./benchmark/run_benchmark.sh

# Generate detailed report
cd benchmark && python3 performance_report.py
```

### Example Workflow
1. **Baseline**: Run benchmark before optimization
2. **Develop**: Implement viewport-based architecture  
3. **Measure**: Run benchmark after changes
4. **Analyze**: Check for improvements/regressions
5. **Document**: Note performance impact in commit message

## ğŸ“‹ Integration with Git

The benchmark system integrates with Git for version tracking:
- Automatically commits uncommitted changes
- Uses commit hash as version identifier
- Tracks performance across development history
- Enables bisecting performance regressions

## ğŸ¯ Performance Targets

### Current Benchmarks (Post-Viewport Architecture - Version 91bc2d8)

#### File Opening Performance
| File Size | Current Performance | Target | Status |
|-----------|-------------------|---------|---------|
| Small (10 items) | 96.94ms Â±12.78 | <50ms | âš ï¸ Needs optimization |
| Medium (50 items) | 190.08ms Â±7.95 | <100ms | âš ï¸ Needs optimization |
| Large (200 items) | 534.81ms Â±52.61 | <200ms | âš ï¸ Needs optimization |
| XLarge (500 items) | 1,326.27ms Â±10.73 | <500ms | âš ï¸ Needs optimization |
| Huge (1000 items) | 2,776.48ms Â±45.18 | <1000ms | âš ï¸ Needs optimization |
| Massive (2000 items) | 5,830.65ms Â±6.86 | <2000ms | âš ï¸ Needs optimization |

#### Tab Switching Performance
| Tab Count | Current Performance | Target | Status |
|-----------|-------------------|---------|---------|
| 2 tabs | 484.25ms Â±60.90 | <50ms | âš ï¸ Needs optimization |
| 3 tabs | 994.23ms Â±21.62 | <100ms | âš ï¸ Needs optimization |
| 5 tabs | 5,112.59ms Â±36.01 | <200ms | âš ï¸ Needs optimization |
| 8 tabs | 10,256.34ms Â±887.04 | <500ms | âš ï¸ Needs optimization |

#### Folding/Unfolding Performance
| Operation | Current Performance | Target | Status |
|-----------|-------------------|---------|---------|
| Fold Level 1-3 | ~485-495ms | <100ms | âš ï¸ Needs optimization |
| Unfold Level 1-3 | ~433-508ms | <100ms | âš ï¸ Needs optimization |

**Memory Usage**: 103.22 MB (Target: <100MB) âš ï¸

### Architecture Status
- âœ… **Error-Free**: Eliminated `'TreeRenderer' object has no attribute 'node_widgets'` errors
- âœ… **Clean Architecture**: Viewport-based design implemented
- âš ï¸ **Performance Regression**: Significant slowdown after architecture changes needs investigation
- ğŸ”§ **Next Steps**: Optimize viewport rendering and caching mechanisms

### Regression Thresholds
- **Critical**: >50% performance degradation
- **Warning**: >10% performance degradation  
- **Acceptable**: <10% variation between runs

## ğŸ”§ Customization

### Adding New Benchmarks
1. Add test function to `benchmark_runner.py`
2. Update `run_full_benchmark()` to include new test
3. Add analysis to `performance_report.py`

### Modifying Test Files
Edit `generate_test_files.py` to change:
- File sizes and complexity
- Content patterns
- Tree depth and structure

### Changing Thresholds
Update regression detection thresholds in:
- `detect_regressions()` function
- Performance targets in this README

## ğŸ“Š Sample Report Output

```
ğŸ” Generating LogLog GUI Performance Report...
ğŸ“Š Loaded 45 benchmark records across 8 versions

=== Performance Trend Analysis ===
file_open           : Latest:   -23.4%, Overall:   -45.2%
tab_switch          : Latest:   -67.8%, Overall:   -89.1%  
fold_level          : Latest:   -12.3%, Overall:   -34.5%

=== Regression Detection (>10% threshold) ===
âœ… No performance regressions detected!

=== Optimization Recommendations ===
âœ… Performance looks good! Consider micro-optimizations.

ğŸ“„ Detailed report saved to: reports/performance_report_20241201_143022.md
```

## ğŸ¤ Contributing

When contributing performance-related changes:
1. **Always run benchmarks** before and after changes
2. **Include performance impact** in commit messages
3. **Investigate regressions** immediately
4. **Document optimization techniques** for future reference

### Commit Message Examples
```
âœ… Good: "Implement viewport architecture - 89% faster tab switching"
âœ… Good: "Optimize folding operations - 34% performance improvement"  
âŒ Bad: "Fixed some performance issues"
```

---

*This benchmarking system helps maintain LogLog's performance standards as the codebase evolves.*